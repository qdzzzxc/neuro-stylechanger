{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf4b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import notebook\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d558e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(path):\n",
    "    images = []\n",
    "    assert os.path.isdir(path), '%s is not a valid directory' % path\n",
    "    for root, _, fnames in sorted(os.walk(path)):\n",
    "        for fname in fnames:\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16301d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3e8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnalignedDataset(Dataset):\n",
    "    ''' Возвращает сразу 2 картинки\n",
    "    Позволяет именть разное количество картинок в датасетах A и B\n",
    "    '''\n",
    "    def __init__(self, dataroot, phase):\n",
    "        self.dir_A = os.path.join(dataroot, phase + 'A')\n",
    "        self.dir_B = os.path.join(dataroot, phase + 'B')\n",
    "\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A))\n",
    "        self.B_paths = sorted(make_dataset(self.dir_B))\n",
    "        self.A_size = len(self.A_paths)\n",
    "        self.B_size = len(self.B_paths)\n",
    "        btoA = True\n",
    "        self.transform_A = transform\n",
    "        self.transform_B = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        \n",
    "        #так как A у нас меньше, чем B\n",
    "        index_B = random.randint(0, self.B_size - 1)\n",
    "        B_path = self.B_paths[index_B]\n",
    "        A_img = Image.open(A_path).convert('RGB')\n",
    "        B_img = Image.open(B_path).convert('RGB')\n",
    "        \n",
    "        A = self.transform_A(A_img)\n",
    "        B = self.transform_B(B_img)\n",
    "\n",
    "        return {'A': A, 'B': B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(self.A_size, self.B_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fd94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(path, phase, batch_size=32):\n",
    "    dataset = UnalignedDataset(path, phase)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6040992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_dataloader('data', 'train')\n",
    "\n",
    "#проверка\n",
    "for batch in dataloader:\n",
    "    print(batch['A'].shape)\n",
    "    print(batch['B'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16f10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код с https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix?tab=readme-ov-file\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1f35fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc29b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3119b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    \"\"\"This class implements an image buffer that stores previously generated images.\n",
    "\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"Initialize the ImagePool class\n",
    "\n",
    "        Parameters:\n",
    "            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"Return an image from the pool.\n",
    "\n",
    "        Parameters:\n",
    "            images: the latest generated images from the generator\n",
    "\n",
    "        Returns images from the buffer.\n",
    "\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)   # collect all the images and return\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f740eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "        loss = self.loss(prediction, target_tensor)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel():\n",
    "    \"\"\"\n",
    "    Используется ResNet генератор\n",
    "    \"\"\"\n",
    "    def __init__(self, isTrain=True, lambda_identity=0.5):\n",
    "        self.optimizers = []\n",
    "        \n",
    "        self.isTrain = isTrain\n",
    "        self.lambda_identity = lambda_identity\n",
    "        \n",
    "        # для каких частей сохранять веса\n",
    "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
    "\n",
    "        # G - генератор, D - дискриминатор\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "        self.netG_A = ResnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False, n_blocks=9).to(device)\n",
    "        self.netG_B = ResnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False, n_blocks=9).to(device)\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.netD_A = NLayerDiscriminator(3, 64, n_layers=3, norm_layer=norm_layer).to(device)\n",
    "            self.netD_B = NLayerDiscriminator(3, 64, n_layers=3, norm_layer=norm_layer).to(device)\n",
    "            \n",
    "            self.fake_A_pool = ImagePool(50)  # позволяют генератору поспевать за дискриминатором\n",
    "            self.fake_B_pool = ImagePool(50)\n",
    "            \n",
    "            self.criterionGAN = GANLoss().to(device)\n",
    "            self.criterionCycle = torch.nn.L1Loss()\n",
    "            self.criterionIdt = torch.nn.L1Loss()\n",
    "\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), \n",
    "                                                lr=3*10**-4, betas=(0.5, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), \n",
    "                                                lr=3*10**-4, betas=(0.5, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        AtoB = False # меняет направление CycleGan\n",
    "        self.real_A = input['A' if AtoB else 'B'].to(device)\n",
    "        self.real_B = input['B' if AtoB else 'A'].to(device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n",
    "        self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))\n",
    "        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n",
    "        self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))\n",
    "\n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "\n",
    "    def backward_D_A(self):\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "\n",
    "    def backward_D_B(self):\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "\n",
    "    def backward_G(self):\n",
    "        lambda_idt = 0.5\n",
    "        lambda_A = 0.5\n",
    "        lambda_B = 0.5\n",
    "        if lambda_idt > 0:\n",
    "            # ||G_A(B) - B||\n",
    "            self.idt_A = self.netG_A(self.real_B)\n",
    "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # ||G_B(A) - A||\n",
    "            self.idt_B = self.netG_B(self.real_A)\n",
    "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "        else:\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # D_A(G_A(A))\n",
    "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
    "        # D_B(G_B(B))\n",
    "        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
    "        # || G_B(G_A(A)) - A||\n",
    "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
    "        # || G_A(G_B(B)) - B||\n",
    "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
    "\n",
    "        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], False)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], True)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D_A()\n",
    "        self.backward_D_B()\n",
    "        self.optimizer_D.step()\n",
    "    \n",
    "    def update_learning_rate(self):\n",
    "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print(f'lr: {old_lr:.5f} -> {lr:.5f}')\n",
    "    \n",
    "    def setup(self, n_epochs, n_epochs_decay, continue_train=False):\n",
    "        if self.isTrain:\n",
    "            # создаёт постепенное уменьшение весов\n",
    "            def lambda_rule(epoch):\n",
    "                lr_l = 1.0 - max(0, epoch - n_epochs) / float(n_epochs_decay + 1)\n",
    "                return lr_l\n",
    "            self.schedulers = [lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule) for optimizer in self.optimizers]\n",
    "            \n",
    "        if continue_train:\n",
    "            load_suffix = 'latest'\n",
    "            self.load_networks(load_suffix)\n",
    "    \n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "    \n",
    "    def save_networks(self, epoch):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                save_path = os.path.join('saves', save_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "\n",
    "                torch.save(net.cpu().state_dict(), save_path)\n",
    "                net.to(device)\n",
    "    \n",
    "    def load_networks(self, epoch):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                load_filename = f'{epoch}_net_{name}.pth'\n",
    "                load_path = os.path.join('saves', load_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "                if isinstance(net, torch.nn.DataParallel):\n",
    "                    net = net.module\n",
    "                print(f'Загружаю модель из {load_path}')\n",
    "\n",
    "                state_dict = torch.load(load_path, map_location=str(device))\n",
    "                if hasattr(state_dict, '_metadata'):\n",
    "                    del state_dict._metadata\n",
    "\n",
    "                # до версии 0.4\n",
    "                for key in list(state_dict.keys()):\n",
    "                    self._patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
    "                net.load_state_dict(state_dict)\n",
    "                \n",
    "    def _patch_instance_norm_state_dict(self, state_dict, module, keys, i=0):\n",
    "        \"\"\"Позволяет использовать сохранения весов с InstanceNorm.\n",
    "        Нужен для версий сохранённых весов до 0.4\"\"\"\n",
    "        key = keys[i]\n",
    "        if i + 1 == len(keys):\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "                    (key == 'running_mean' or key == 'running_var'):\n",
    "                if getattr(module, key) is None:\n",
    "                    state_dict.pop('.'.join(keys))\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "                    (key == 'num_batches_tracked'):\n",
    "                state_dict.pop('.'.join(keys))\n",
    "        else:\n",
    "            self._patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ea18f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаю модель из saves\\latest_net_G_A.pth\n",
      "Загружаю модель из saves\\latest_net_G_B.pth\n",
      "Загружаю модель из saves\\latest_net_D_A.pth\n",
      "Загружаю модель из saves\\latest_net_D_B.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa299d064da4d749225d4f210df2bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.00030 -> 0.00030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Никита\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716142181c2f4171a3157fb321c81bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняю веса модели после 0 эпохи\n",
      "Конец эпохи: 0 / 3 \t Заняло времени: 2875.011278152466 секунд\n",
      "lr: 0.00030 -> 0.00030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522922e8c705476d93cb5cfe2145cd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняю веса модели после 1 эпохи\n",
      "Конец эпохи: 1 / 3 \t Заняло времени: 2534.997329711914 секунд\n",
      "lr: 0.00030 -> 0.00030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9a9c62d322493d9a9758cf2fc96913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняю веса модели после 2 эпохи\n",
      "Конец эпохи: 2 / 3 \t Заняло времени: 2535.2069556713104 секунд\n",
      "lr: 0.00030 -> 0.00015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39bfd284cea435f83671bce3c75ce10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняю веса модели после 3 эпохи\n",
      "Конец эпохи: 3 / 3 \t Заняло времени: 2541.0024225711823 секунд\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3 # обычные эпохи\n",
    "n_epochs_decay = 1 # эпохи с уменьшением lr\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "batch_size = 1\n",
    "dataloader = get_dataloader('data', 'train', batch_size)\n",
    "dataloader_size = len(dataloader)\n",
    "\n",
    "model = CycleGANModel()\n",
    "model.setup(n_epochs, n_epochs_decay, continue_train=True) #continue_train - загружаем уже натренированные ранее веса!\n",
    "\n",
    "for epoch in notebook.tqdm(range(n_epochs + n_epochs_decay)):\n",
    "    epoch_start_time = time.time()\n",
    "    model.update_learning_rate()    # проходимся по чедулерам\n",
    "    for data in notebook.tqdm(dataloader):\n",
    "        model.set_input(data)       #data.to ...\n",
    "        model.optimize_parameters()\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Сохраняю веса модели после {epoch} эпохи')\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    print(f'Конец эпохи: {epoch} / {n_epochs} \\t Заняло времени: {time.time() - epoch_start_time} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34106b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_networks('latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a7880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
